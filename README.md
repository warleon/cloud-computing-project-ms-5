# DataLake Architecture - AWS Cloud Project

Arquitectura completa de DataLake desplegada en **EC2 Ubuntu 22.04** con ingesta de datos desde mÃºltiples fuentes, catalogaciÃ³n con Glue y consultas analÃ­ticas vÃ­a API REST.

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      EC2 Ubuntu 22.04                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Docker Containers (7 servicios)                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ MySQL 8.0         (puerto 3307)                  â”‚   â”‚
â”‚  â”‚  â”œâ”€ PostgreSQL 15     (puerto 5433)                  â”‚   â”‚
â”‚  â”‚  â”œâ”€ MongoDB 7.0       (puerto 27018)                 â”‚   â”‚
â”‚  â”‚  â”œâ”€ Ingester MySQL    (ingesta01-mysql)              â”‚   â”‚
â”‚  â”‚  â”œâ”€ Ingester PostgreSQL (ingesta02-postgresql)       â”‚   â”‚
â”‚  â”‚  â”œâ”€ Ingester MongoDB  (ingesta03-mongodb)            â”‚   â”‚
â”‚  â”‚  â””â”€ API REST FastAPI  (puerto 8000)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â†“ boto3 (JSON Lines)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Amazon S3 (3 Buckets)        â”‚
        â”‚  â”œâ”€ raw-ms1-data-bgc (MySQL)         â”‚
        â”‚  â”œâ”€ raw-ms2-data-bgc (PostgreSQL)    â”‚
        â”‚  â””â”€ raw-ms3-data-bgc (MongoDB)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“ AWS Glue Crawlers
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   AWS Glue Data Catalog (9 tablas)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“ Athena SQL Queries
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Amazon Athena (Query Engine)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“ API REST (15+ endpoints)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Usuarios/Aplicaciones           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
cloud-m5/
â”‚
â”œâ”€â”€ docker-compose.yml         # Orquestador maestro (usa 'include')
â”œâ”€â”€ deploy-all.sh              # Script de despliegue para Ubuntu/Linux
â”œâ”€â”€ .gitignore                 # Protege .env y archivos sensibles
â”‚
â”œâ”€â”€ ms-databases/              # 3 bases de datos de prueba
â”‚   â”œâ”€â”€ docker-compose.yml     # MySQL, PostgreSQL, MongoDB
â”‚   â”œâ”€â”€ .env                   # Credenciales de BD (gitignored)
â”‚   â”œâ”€â”€ .env.example           # Plantilla para configurar
â”‚   â”œâ”€â”€ init-mysql.sql         # Datos de prueba MS1
â”‚   â”œâ”€â”€ init-postgres.sql      # Datos de prueba MS2
â”‚   â”œâ”€â”€ init-mongo.js          # Datos de prueba MS3
â”‚   â””â”€â”€ README.md              # DocumentaciÃ³n detallada
â”‚
â”œâ”€â”€ datalake-ingester/         # ETL: Extrae y sube a S3
â”‚   â”œâ”€â”€ docker-compose.yml     # 3 ingesters (uno por DB)
â”‚   â”œâ”€â”€ ingester.py            # LÃ³gica de ingesta (boto3)
â”‚   â”œâ”€â”€ .env                   # AWS credentials + S3 buckets
â”‚   â”œâ”€â”€ .env.example           # Plantilla
â”‚   â”œâ”€â”€ requirements.txt       # boto3, pymysql, psycopg2, pymongo
â”‚   â””â”€â”€ README.md              # DocumentaciÃ³n ETL
â”‚
â””â”€â”€ api-consultas/             # API REST con FastAPI
    â”œâ”€â”€ docker-compose.yml     # Servicio API (puerto 8000)
    â”œâ”€â”€ main.py                # Endpoints de FastAPI
    â”œâ”€â”€ athena_client.py       # Cliente para consultas Athena
    â”œâ”€â”€ queries.py             # Queries SQL predefinidas
    â”œâ”€â”€ .env                   # AWS credentials + config Athena
    â”œâ”€â”€ .env.example           # Plantilla
    â”œâ”€â”€ requirements.txt       # fastapi, boto3, uvicorn
    â”œâ”€â”€ DataLake_API_Postman_Collection.json  # 16 requests
    â””â”€â”€ README.md              # DocumentaciÃ³n API con endpoints
```

## ï¿½ Arquitectura de Redes Docker

### Conectividad Entre Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Red: datalake-network                  â”‚
â”‚          (ComunicaciÃ³n interna)                 â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ MySQL    â”‚  â”‚PostgreSQL â”‚  â”‚ MongoDB  â”‚    â”‚
â”‚  â”‚ :3306    â”‚  â”‚  :5432    â”‚  â”‚ :27017   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚       â†‘              â†‘              â†‘          â”‚
â”‚       â”‚   ConexiÃ³n directa via    â”‚          â”‚
â”‚       â”‚   nombres de contenedores  â”‚          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                      â”‚                         â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚           â”‚  Ingester Containers â”‚             â”‚
â”‚           â”‚  - ingesta01-mysql   â”‚             â”‚
â”‚           â”‚  - ingesta02-postgresâ”‚             â”‚
â”‚           â”‚  - ingesta03-mongodb â”‚             â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  API-Consultas  â”‚  â† NO necesita red Docker
        â”‚    :8000        â”‚     (solo se comunica con AWS)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â†“ HTTPS (boto3)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Amazon Athena  â”‚
        â”‚  (AWS Cloud)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â†“ Query S3
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Amazon S3     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Â¿QuiÃ©n necesita estar en la red Docker?

| Componente | Red Docker | RazÃ³n |
|------------|------------|-------|
| **ms-databases** | âœ… `datalake-network` | Crea la red para que otros componentes se conecten |
| **datalake-ingester** | âœ… `datalake-network` | Necesita conectarse directamente a las 3 bases de datos usando nombres de contenedores (`mysql-db`, `postgres-db`, `mongo-db`) |
| **api-consultas** | âŒ **NO necesita red** | Solo se comunica con Amazon Athena (servicio AWS en la nube). No accede directamente a las bases de datos |

### Flujo de Conexiones

1. **Ingesters â†’ Bases de Datos**: ConexiÃ³n directa dentro de `datalake-network`
   - Host: `mysql-db`, `postgres-db`, `mongo-db` (nombres de contenedores)
   - ComunicaciÃ³n: TCP interno de Docker

2. **Ingesters â†’ S3**: ConexiÃ³n HTTPS vÃ­a boto3 SDK
   - Usa IAM Role del EC2 para autenticaciÃ³n
   - No requiere credenciales hardcoded

3. **API â†’ Athena/S3**: ConexiÃ³n HTTPS vÃ­a boto3 SDK
   - Usa IAM Role del EC2 para autenticaciÃ³n
   - Lee datos desde S3 vÃ­a queries Athena
   - **Nunca accede directamente a las bases de datos**

### ConfiguraciÃ³n de Red con `include`

Cuando se usa `include` en Docker Compose (como en este proyecto):

1. **El archivo raÃ­z** (`docker-compose.yml`) define la red:
   ```yaml
   networks:
     datalake-network:
       driver: bridge
   ```

2. **Los archivos individuales** referencian la red pero **NO la definen**:
   ```yaml
   services:
     mysql-db:
       networks:
         - datalake-network
   
   # âŒ NO incluir secciÃ³n "networks:" al final del archivo
   ```

3. **La red se crea automÃ¡ticamente** al ejecutar:
   ```bash
   docker-compose up -d
   ```

**Importante**: Los archivos `ms-databases/docker-compose.yml` y `datalake-ingester/docker-compose.yml` solo **referencian** la red en los servicios, pero no la definen al final. Esto evita conflictos con el `include`.

## ï¿½ğŸš€ Inicio RÃ¡pido en EC2 Ubuntu

### Pre-requisitos

1. **EC2 Ubuntu 22.04** (t2.medium o superior recomendado)
2. **IAM Role** con permisos S3, Glue y Athena (ej: `LabRole` para AWS Academy)
3. **3 Buckets S3** creados:
   - `raw-ms1-data-bgc` (para MySQL)
   - `raw-ms2-data-bgc` (para PostgreSQL)
   - `raw-ms3-data-bgc` (para MongoDB)
4. **Docker y Docker Compose instalados** en EC2

### InstalaciÃ³n de Docker en Ubuntu

```bash
# Actualizar sistema
sudo apt update && sudo apt upgrade -y

# Instalar Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Agregar usuario al grupo docker (evita usar sudo)
sudo usermod -aG docker $USER
newgrp docker

# Verificar instalaciÃ³n
docker --version
docker compose version
```

### 1. Clonar el Proyecto y Configurar Variables

```bash
# Clonar repositorio
git clone <tu-repositorio-url>
cd cloud-m5

# Configurar variables de entorno en cada componente
cd ms-databases
cp .env.example .env
nano .env  # Editar credenciales

cd ../datalake-ingester
cp .env.example .env
nano .env  # Configurar AWS credentials y buckets S3

cd ../api-consultas
cp .env.example .env
nano .env  # Configurar AWS credentials y Athena

cd ..  # Volver a raÃ­z
```

**âš ï¸ IMPORTANTE**: Los archivos `.env` contienen credenciales reales y NO se suben a Git.

### 2. Desplegar Todos los Servicios

#### Verificar versiÃ³n de Docker Compose

```bash
# Docker Compose V2 (mÃ¡s reciente - integrado con Docker)
docker compose version

# Docker Compose V1 (versiÃ³n antigua - comando separado)
docker-compose --version
```

**Nota**: Los comandos cambian segÃºn la versiÃ³n:
- **V2**: `docker compose` (con espacio)
- **V1**: `docker-compose` (con guiÃ³n)

En los ejemplos siguientes usaremos **V1** (`docker-compose`), si tienes V2 usa `docker compose`.

#### OpciÃ³n A: Docker Compose desde la RaÃ­z (MÃ¡s Simple)

```bash
# Levanta TODOS los servicios (7 contenedores)
docker compose up -d

# Ver estado
docker compose ps

# Ver logs en tiempo real
docker compose logs -f

# Detener todo
docker compose down
```

#### OpciÃ³n B: Script Bash con Comandos Ãštiles

```bash
# Dar permisos de ejecuciÃ³n
chmod +x deploy-all.sh

# Levantar todos los servicios (con espera de 15s para DBs)
./deploy-all.sh start

# Ver estado de todos los contenedores
./deploy-all.sh status

# Ver logs de todos los servicios
./deploy-all.sh logs

# Detener todos los servicios
./deploy-all.sh stop

# Reiniciar todos los servicios
./deploy-all.sh restart

# Reconstruir contenedores despuÃ©s de cambios
./deploy-all.sh rebuild
```

### 3. Configurar AWS Glue (Desde AWS Console)

```bash
# 1. Crear base de datos en Glue
aws glue create-database --database-input '{"Name": "datalake_db"}'

# 2. Crear y ejecutar 3 crawlers (uno por bucket S3)
# Configurar desde AWS Console:
#   - Crawler 1: raw-ms1-data-bgc â†’ tabla: ms1_*
#   - Crawler 2: raw-ms2-data-bgc â†’ tabla: ms2_*
#   - Crawler 3: raw-ms3-data-bgc â†’ tabla: ms3_*

# 3. Ejecutar crawlers para catalogar datos
# Resultado esperado: 9 tablas en Glue Data Catalog
```

### 4. Verificar Despliegue

```bash
# Ver contenedores corriendo (deberÃ­as ver 7)
docker ps

# Probar bases de datos
docker logs mysql-test-db
docker logs postgres-test-db
docker logs mongo-test-db

# Probar ingesters (deben ejecutarse y terminar)
docker logs ingesta01-mysql
docker logs ingesta02-postgresql
docker logs ingesta03-mongodb

# Probar API REST
curl http://localhost:8000/health
# Respuesta esperada: {"status":"healthy"}

# Ver Swagger UI en navegador
# http://<IP-PUBLICA-EC2>:8000/docs
```

## ï¿½ Servicios Desplegados

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| **mysql-test-db** | 3307 | MySQL 8.0 con datos de MS1 (usuarios, pedidos, productos) |
| **postgres-test-db** | 5433 | PostgreSQL 15 con datos de MS2 (clientes, facturas, pagos) |
| **mongo-test-db** | 27018 | MongoDB 7.0 con datos de MS3 (logs, sesiones, eventos) |
| **ingesta01-mysql** | - | Extrae MySQL â†’ S3 (formato JSON Lines) |
| **ingesta02-postgresql** | - | Extrae PostgreSQL â†’ S3 (formato JSON Lines) |
| **ingesta03-mongodb** | - | Extrae MongoDB â†’ S3 (formato JSON Lines) |
| **api-consultas-datalake** | 8000 | API REST con 15+ endpoints (Athena queries) |

## ğŸŒ API REST - Endpoints Principales

Accede a la documentaciÃ³n interactiva: **`http://<EC2-IP>:8000/docs`**

### Endpoints Disponibles:

- `GET /health` - Health check
- `GET /api/dashboard` - Dashboard general con mÃ©tricas
- `GET /api/usuarios` - Listar usuarios (MS1)
- `GET /api/pedidos` - Listar pedidos (MS1)
- `GET /api/productos` - Listar productos (MS1)
- `GET /api/clientes` - Listar clientes (MS2)
- `GET /api/facturas` - Listar facturas (MS2)
- `GET /api/pagos` - Listar pagos (MS2)
- `GET /api/logs` - Listar logs (MS3)
- `GET /api/sesiones` - Listar sesiones (MS3)
- `GET /api/eventos` - Listar eventos (MS3)
- `GET /api/pedidos/{pedido_id}` - Pedido por ID
- `GET /api/productos-por-categoria/{categoria}` - Productos filtrados
- `GET /api/facturas-por-cliente/{cliente_id}` - Facturas de cliente
- `POST /api/query-custom` - Ejecutar query SQL personalizada

**ğŸ“¥ Importar Postman Collection**: `api-consultas/DataLake_API_Postman_Collection.json` (16 requests listos)

## ğŸ“š DocumentaciÃ³n Detallada por Componente

- **[ms-databases/README.md](./ms-databases/README.md)** - Bases de datos, esquemas, datos de prueba
- **[datalake-ingester/README.md](./datalake-ingester/README.md)** - Ingesters, formato JSON Lines, particiones S3
- **[api-consultas/README.md](./api-consultas/README.md)** - API REST, endpoints, Athena queries, ejemplos

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­a | VersiÃ³n |
|-----------|------------|---------|
| **Cloud** | AWS S3, Glue, Athena, EC2, IAM | - |
| **Lenguaje** | Python | 3.11 |
| **Framework API** | FastAPI | 0.104.1 |
| **SDK AWS** | boto3 | 1.34.0 |
| **Bases de Datos** | MySQL | 8.0 |
| | PostgreSQL | 15 |
| | MongoDB | 7.0 |
| **ContainerizaciÃ³n** | Docker | 24.x |
| | Docker Compose | v3.8 |
| **Formato de Datos** | JSON Lines (NDJSON) | - |

## ğŸ” Seguridad y Buenas PrÃ¡cticas

### Archivos Protegidos (`.gitignore`):
- âœ… `.env` - Credenciales reales
- âœ… `*.pem`, `*.ppk` - Llaves SSH
- âœ… `notes.txt` - Notas personales
- âœ… `mysql-data/`, `postgres-data/`, `mongo-data/` - VolÃºmenes de datos

### Credenciales AWS:
- Usa **IAM Roles** en EC2 (no hardcodear access keys)
- Para AWS Academy usa `LabRole` / `LabInstanceProfile`
- Rota credenciales regularmente

## ğŸ”§ Comandos Ãštiles

```bash
# Ver logs de un servicio especÃ­fico
docker logs -f <nombre-contenedor>

# Reiniciar un servicio
docker compose restart <nombre-servicio>

# Reconstruir despuÃ©s de cambios en cÃ³digo
docker compose up -d --build

# Detener y eliminar volÃºmenes (âš ï¸ elimina datos de BD)
docker compose down -v

# Ver uso de recursos
docker stats

# Limpiar contenedores detenidos
docker system prune -a

# Ver redes Docker
docker network ls

# Inspeccionar un contenedor
docker inspect <nombre-contenedor>
```

## ğŸ› Troubleshooting

### Error: "networks.datalake-network conflicts with imported resource"

Este error ocurre cuando mÃºltiples archivos docker-compose intentan definir la misma red.

**SoluciÃ³n**: La red debe definirse **solo en el archivo raÃ­z** (`docker-compose.yml`):

```yaml
# docker-compose.yml (raÃ­z)
networks:
  datalake-network:
    driver: bridge
```

Los archivos individuales (`ms-databases/`, `datalake-ingester/`) **NO** deben tener secciÃ³n `networks:` al final, solo referencian la red en los servicios.

```bash
# Si persiste el error, limpiar y reiniciar:
docker-compose down
docker network prune -f
docker-compose up -d
```

**Nota importante**: Solo los **ingesters** y **bases de datos** necesitan estar en la red `datalake-network`. La **API** no necesita esta red porque solo se comunica con Athena (AWS).

### Error: "Cannot connect to Docker daemon"
```bash
# Verificar que Docker estÃ© corriendo
sudo systemctl status docker

# Iniciar Docker
sudo systemctl start docker

# Agregar usuario al grupo docker
sudo usermod -aG docker $USER
newgrp docker
```

### Error: "The container name is already in use"

Este error ocurre cuando hay contenedores de intentos anteriores que no se eliminaron.

```bash
# Detener todos los servicios
docker-compose down

# Eliminar contenedores especÃ­ficos que quedaron
docker rm -f $(docker ps -aq --filter "name=ingesta") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=mysql-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=postgres-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=mongo-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=api-consultas") 2>/dev/null || true

# Limpiar redes huÃ©rfanas
docker network prune -f

# Levantar servicios limpios
docker-compose up -d
```

### Error: "Port already in use"
```bash
# Ver quÃ© proceso usa el puerto
sudo lsof -i :8000

# O cambiar puerto en .env del servicio
```

### Error: "Permission denied" en S3
- Verifica que el IAM Role en EC2 tenga polÃ­ticas: `AmazonS3FullAccess`, `AWSGlueConsoleFullAccess`, `AmazonAthenaFullAccess`
- Revisa que los buckets existan en la regiÃ³n correcta (us-east-1)
- Verifica credenciales en archivos `.env`

### Athena devuelve errores de tipos de datos
- Verifica que los datos en S3 estÃ©n en **JSON Lines** (no JSON pretty-printed)
- Ejecuta los Glue Crawlers para actualizar el esquema
- Los ingesters ya convierten `Decimal` â†’ `float` y `datetime` â†’ `ISO string`

### Ingesters no suben datos a S3
```bash
# Ver logs de ingesters
docker logs ingesta01-mysql
docker logs ingesta02-postgresql
docker logs ingesta03-mongodb

# Verificar conectividad con AWS
aws s3 ls s3://raw-ms1-data-bgc/

# Revisar .env en datalake-ingester/
```

### Warnings: "AWS_ACCESS_KEY_ID variable is not set"
Estos warnings son **normales y esperados** si usas IAM Role en EC2:
```
WARN[0000] The "AWS_ACCESS_KEY_ID" variable is not set. Defaulting to a blank string.
WARN[0000] The "AWS_SECRET_ACCESS_KEY" variable is not set. Defaulting to a blank string.
WARN[0000] The "AWS_SESSION_TOKEN" variable is not set. Defaulting to a blank string.
```

**Puedes ignorarlos** porque:
- El EC2 usa IAM Role (`LabRole`) para autenticaciÃ³n automÃ¡tica
- No necesitas credenciales hardcoded en los `.env`
- Los servicios obtienen credenciales temporales del EC2 metadata service

Si prefieres eliminar los warnings, deja las variables vacÃ­as en los `.env`:
```bash
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=
```

### API devuelve 500 Internal Server Error
```bash
# Ver logs de la API
docker logs api-consultas-datalake

# Verificar que Glue Data Catalog tenga tablas
aws glue get-tables --database-name datalake_db

# Verificar .env en api-consultas/
```

## ğŸ“ Limitaciones de AWS Academy

- âš ï¸ **No puedes crear IAM Roles nuevos** â†’ Usa `LabRole` existente
- âš ï¸ **Sesiones expiran despuÃ©s de 4 horas** â†’ Re-inicia la lab
- âš ï¸ **Algunos servicios estÃ¡n restringidos** (Lambda, RDS managed, etc.)
- âœ… **S3, Glue, Athena y EC2 funcionan perfectamente**

## ğŸ¤ ContribuciÃ³n

```bash
# 1. Copiar plantillas de variables
cp ms-databases/.env.example ms-databases/.env
cp datalake-ingester/.env.example datalake-ingester/.env
cp api-consultas/.env.example api-consultas/.env

# 2. Configurar credenciales reales (NO subir a Git)

# 3. Hacer cambios en cÃ³digo

# 4. Probar localmente
docker compose up -d --build

# 5. Asegurarse que .env estÃ© en .gitignore

# 6. Commit y push (sin .env)
git add .
git commit -m "descripciÃ³n"
git push
```

## ğŸ“„ Licencia

Proyecto educativo para AWS Academy - Cloud Computing.

---

**Desarrollado con â˜ï¸ para aprender arquitecturas DataLake en AWS**
